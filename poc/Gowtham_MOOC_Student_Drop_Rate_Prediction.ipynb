{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOOC_Student_Drop_Rate_Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "# Loading the data\n",
    "data = pd.read_csv('MOOC_Visual.csv', parse_dates=['startdate', 'enddate'])\n",
    "# Removing duplicate rows\n",
    "duplicate_index = data[data.drop(['enrollment_id', 'startdate', 'enddate'], axis=1).duplicated()].index\n",
    "data = data.drop(duplicate_index)\n",
    "# Removing Outliers\n",
    "data = data[data['access']<700]\n",
    "data = data[data['discussion']<1000]\n",
    "data = data[data['navigate']<200]\n",
    "data = data[data['page_close']<250]\n",
    "data = data[data['problem']<750]\n",
    "data = data[data['video']<250]\n",
    "data = data[data['wiki']<120]\n",
    "data = data[data['effective_time']<255]\n",
    "# Droping independent features\n",
    "data.drop(['page_close', 'video', 'proccess_period'], axis=1, inplace=True)\n",
    "# Extracting extra feature from Start_Date and End_Date\n",
    "duration_in_days = (data['enddate'] - data['startdate']).dt.days + 1\n",
    "data.insert(8,\"duration_in_days\", duration_in_days)\n",
    "# Splitting the data using train_test_split\n",
    "train, test = train_test_split(data.iloc[:, 3:], test_size=0.3, random_state=0)\n",
    "X_test = test.drop(['dropout_prob'], axis=1)\n",
    "y_test = test['dropout_prob']\n",
    "# Upsampling data i.e., Minor to Major\n",
    "dropout_minor = train[train.dropout_prob==0]\n",
    "dropout_major = train[train.dropout_prob==1]\n",
    "dropout_upsampled = resample(dropout_minor,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(dropout_major), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([dropout_major, dropout_upsampled])\n",
    "y_train = upsampled.dropout_prob\n",
    "X_train = upsampled.drop(['dropout_prob'], axis=1)\n",
    "X_train = X_train[['duration_in_days', 'access', 'discussion', 'navigate', 'problem', 'wiki', 'present_days', 'effective_time', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', 'holidays', 'course_enroll', 'user_enroll', 'course_drop_rate']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting result with RandomForestClassifier\n",
    "classifier = RandomForestClassifier(criterion = 'entropy', random_state = 10)\n",
    "classifier.fit(X_train, y_train)\n",
    "print(\"Training Score : \", classifier.score(X_train, y_train))\n",
    "print(\"Testing Score : \", classifier.score(X_test, y_test))\n",
    "\n",
    "# Generating Pickle file\n",
    "pickle.dump(classifier, open('pkl_rfc_mim.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import math\n",
    "\n",
    "# Loading the data\n",
    "data = pd.read_csv('MOOC_Visual.csv', parse_dates=['startdate', 'enddate'])\n",
    "# Removing duplicate rows\n",
    "duplicate_index = data[data.drop('enrollment_id', axis=1).duplicated()].index\n",
    "data = data.drop(duplicate_index)\n",
    "# Removing Outliers\n",
    "data = data[data['access']<700]\n",
    "data = data[data['discussion']<1000]\n",
    "data = data[data['navigate']<200]\n",
    "data = data[data['page_close']<250]\n",
    "data = data[data['problem']<750]\n",
    "data = data[data['video']<250]\n",
    "data = data[data['wiki']<120]\n",
    "data = data[data['effective_time']<255]\n",
    "\n",
    "# Extracting extra feature from Start_Date and End_Date\n",
    "duration_in_days = (data['enddate'] - data['startdate']).dt.days + 1\n",
    "data.insert(11,\"duration_in_days\", duration_in_days)\n",
    "\n",
    "# Exclude independent features ('page_close', 'video', 'proccess_period') which are highly correlated \n",
    "# Include independent features ('effective_time', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday', 'holidays', 'course_enroll', 'user_enroll', 'course_drop_rate') \n",
    "data = data[['duration_in_days', 'present_days', 'access', 'discussion', 'navigate', 'problem', 'wiki', 'dropout_prob']]\n",
    "\n",
    "# Spliting Input and Output features and scaling X data and concatenate into \"data\"\n",
    "y = data['dropout_prob']\n",
    "X = data.drop('dropout_prob', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log\n",
    "X_log = np.log(X+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing\n",
    "X_norm = preprocessing.normalize(X_log)\n",
    "X_norm = pd.DataFrame(X_norm, index= X.index, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the Input features\n",
    "ss_scale = StandardScaler()\n",
    "X_scale = scale.fit_transform(X_norm)\n",
    "X_scale = pd.DataFrame(X_scale, index=X.index, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([X_scale, y], axis=1)\n",
    "# Splitting training and testing data using train_test_split()\n",
    "train, test = train_test_split(data, test_size=0.3, random_state=0)\n",
    "X_test = test.drop(['dropout_prob'], axis=1)\n",
    "y_test = test['dropout_prob']\n",
    "# Upsampling data i.e., Minor to Major\n",
    "dropout_minor = train[train.dropout_prob==0]\n",
    "dropout_major = train[train.dropout_prob==1]\n",
    "dropout_upsampled = resample(dropout_minor,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(dropout_major), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([dropout_major, dropout_upsampled])\n",
    "y_train = upsampled.dropout_prob\n",
    "X_train = upsampled.drop(['dropout_prob'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score :  0.9362165008452734\n",
      "Testing Score :  0.8066576155277316\n"
     ]
    }
   ],
   "source": [
    "# Predicting result with RandomForestClassifier\n",
    "classifier = RandomForestClassifier(criterion = 'entropy', random_state = 10)\n",
    "classifier.fit(X_train, y_train)\n",
    "# Generating Pickle file\n",
    "pickle.dump(classifier, open('pkl_rfc_log_norm_scale_ggm.pkl', 'wb'))\n",
    "print(\"Training Score : \", classifier.score(X_train, y_train))\n",
    "print(\"Testing Score : \", classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('MOOC_Visual.csv', parse_dates=['startdate', 'enddate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['duration_in_days', 'present_days', 'access', 'discussion', 'navigate',\n",
       "       'problem', 'wiki'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startdate</th>\n",
       "      <th>enddate</th>\n",
       "      <th>present_days</th>\n",
       "      <th>access</th>\n",
       "      <th>discussion</th>\n",
       "      <th>navigate</th>\n",
       "      <th>problem</th>\n",
       "      <th>wiki</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2014-06-02</td>\n",
       "      <td>2014-06-03</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    startdate    enddate  present_days  access  discussion  navigate  problem  \\\n",
       "30 2014-06-02 2014-06-03             2       8           0         6        0   \n",
       "\n",
       "    wiki  \n",
       "30     0  "
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[['startdate', 'enddate', 'present_days', 'access', 'discussion', 'navigate', 'problem', 'wiki']].iloc[30:31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open(\"pkl_rfc_log_norm_scale_ggm.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8660254 ,  0.8660254 ,  0.8660254 , -1.15470054,  0.8660254 ,\n",
       "        -1.15470054, -1.15470054]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
